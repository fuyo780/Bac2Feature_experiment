{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation for evaluating predicion accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment settings\n",
    "```sh\n",
    "# Working Directory\n",
    "cd Bac2fFeature/scripts/03_cross_validation\n",
    "# Conda environment\n",
    "conda activate bac2feature_experiment\n",
    "# Output Directory\n",
    "directories=(\n",
    "    \"../../data/cross_validation\"\n",
    "    \"../../data/cross_validation_vr\"\n",
    ")\n",
    "for dir in \"${directories[@]}\"; do\n",
    "  if [ ! -d \"$dir\" ]; then\n",
    "    mkdir -p \"$dir\"\n",
    "  fi\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon, friedmanchisquare\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "matplotlib.rcParams['font.sans-serif'] = [\"Arial\", \"DejaVu Sans\", \"Lucida Grande\", \"Verdana\"]\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [4, 3]\n",
    "matplotlib.rcParams[\"font.size\"] = 10\n",
    "matplotlib.rcParams[\"axes.labelcolor\"] = \"#000000\"\n",
    "matplotlib.rcParams[\"axes.linewidth\"] = 1.0\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 1.0\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 1.0\n",
    "\n",
    "cmap1 = plt.cm.tab20\n",
    "cmap2 = plt.cm.Set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous traits\n",
    "nt = ['cell_diameter', 'cell_length', 'doubling_h', 'growth_tmp', 'optimum_tmp', 'optimum_ph', 'genome_size', 'gc_content', 'coding_genes', 'rRNA16S_genes', 'tRNA_genes']\n",
    "# Categorical traits\n",
    "ct = ['gram_stain',\n",
    "      'sporulation', 'motility', 'range_salinity', 'facultative_respiration',\n",
    "      'anaerobic_respiration', 'aerobic_respiration', 'mesophilic_range_tmp',\n",
    "      'thermophilic_range_tmp', 'psychrophilic_range_tmp',\n",
    "      'bacillus_cell_shape', 'coccus_cell_shape', 'filament_cell_shape',\n",
    "      'coccobacillus_cell_shape', 'vibrio_cell_shape', 'spiral_cell_shape']\n",
    "# Visualization titles of traits\n",
    "titles = {'cell_diameter': 'Cell diameter', 'cell_length': 'Cell length', 'doubling_h': 'Doubling time', 'growth_tmp': 'Growth temp.', 'optimum_tmp': 'Optimum temp.', 'optimum_ph': 'Optimum pH', 'genome_size': 'Genome size', 'gc_content': 'GC content', 'coding_genes': 'Coding genes', 'rRNA16S_genes': 'rRNA16S genes', 'tRNA_genes': 'tRNA genes', 'gram_stain': 'Gram stain', 'sporulation': 'Sporulation', 'motility': 'Motility', 'range_salinity': 'Halophile', 'facultative_respiration': 'Facultative', 'anaerobic_respiration': 'Anaerobe', 'aerobic_respiration':'Aerobe' ,'mesophilic_range_tmp': 'Mesophile', 'thermophilic_range_tmp':'Thermophile', 'psychrophilic_range_tmp': 'Psychrophile', 'bacillus_cell_shape': 'Bacillus', 'coccus_cell_shape': 'Coccus', 'filament_cell_shape': 'Filament', 'coccobacillus_cell_shape': 'Coccobacillus', 'vibrio_cell_shape': 'Vibrio', 'spiral_cell_shape': 'Spiral'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing cross-validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 16S rRNA gene sequences and trait data\n",
    "```sh\n",
    "# Extract header ID of 16S rRNA sequences\n",
    "seqkit seq -n ../../data/intermediate_dir/silva_msa_trim.fasta > ../../data/cross_validation/header.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset for 10-fold cross validation\n",
    "random.seed(0)\n",
    "out_dir = '../../data/cross_validation'\n",
    "## Use header for sequences' ID\n",
    "header = pd.read_csv(\"../../data/cross_validation/header.txt\", names=[\"header\"], dtype=str)\n",
    "l_header = list(header[\"header\"].values)\n",
    "l_header_shuffled = random.sample(l_header, len(l_header))\n",
    "## Split\n",
    "trait_table = pd.read_csv(\"../../data/ref_bac2feature/trait_bac2feature.tsv\", sep=\"\\t\", dtype=str)\n",
    "for i, test_header in enumerate(np.array_split(l_header_shuffled, 10)):\n",
    "    # Path\n",
    "    split_dir = os.path.join(out_dir, f\"split_{i}\")\n",
    "    if not os.path.exists(split_dir):\n",
    "        os.makedirs(split_dir)\n",
    "    test_header_path = os.path.join(split_dir, \"nodeid_test.txt\")\n",
    "    ref_header_path = os.path.join(split_dir, \"nodeid_ref.txt\")\n",
    "    ref_trait_path = os.path.join(split_dir, \"traits.tsv\")\n",
    "    # Split header\n",
    "    set_test_header = set(test_header)\n",
    "    ref_header = [h for h in l_header if h not in set_test_header]\n",
    "    with open(test_header_path, 'w') as f:\n",
    "        f.write('\\n'.join(test_header))\n",
    "    with open(ref_header_path, 'w') as f:\n",
    "        f.write('\\n'.join(ref_header))\n",
    "    # Split trait table\n",
    "    is_ref = trait_table[\"species_tax_id\"].apply(\n",
    "                 lambda x: x not in set_test_header)\n",
    "    trait_table[is_ref].to_csv(ref_trait_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# Split full 16S rRNA sequences into test and reference data\n",
    "for i in $(seq 0 9); do seqkit grep -nf ../../data/cross_validation/split_$i/nodeid_test.txt ../../data/intermediate_dir/SILVA_138.1_SSURef_NR99_tax_silva_taxid.fasta > ../../data/cross_validation/split_$i/test_seq_full.fasta; done\n",
    "for i in $(seq 0 9); do seqkit grep -nf ../../data/cross_validation/split_$i/nodeid_ref.txt ../../data/intermediate_dir/SILVA_138.1_SSURef_NR99_tax_silva_taxid.fasta > ../../data/cross_validation/split_$i/ref_seq_full.fasta; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing reference dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homology-based prediction\n",
    "```sh\n",
    "for i in $(seq 0 9); do makeblastdb -in ../../data/cross_validation/split_$i/ref_seq_full.fasta -out ../../data/cross_validation/split_$i/blastdb/ref_seq_full -dbtype nucl; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxonomy-based prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trait table\n",
    "trait_path = \"../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "trait = pd.read_csv(trait_path, sep=\"\\t\", dtype=str)\n",
    "# SILVA taxonomy\n",
    "silva_metadata_path = \"../../data/intermediate_dir/silva_taxonomy.tsv\"\n",
    "silva_metadata = pd.read_csv(silva_metadata_path, sep=\"\\t\", dtype=str)\n",
    "silva_metadata.fillna(\"\", inplace=True)\n",
    "silva_metadata[\"taxonomy\"] = (\"k__\" + silva_metadata[\"superkingdom\"] +\n",
    "                              \"; p__\" + silva_metadata[\"phylum\"] +\n",
    "                              \"; c__\" + silva_metadata[\"class\"] +\n",
    "                              \"; o__\" + silva_metadata[\"order\"] +\n",
    "                              \"; f__\" + silva_metadata[\"family\"] +\n",
    "                              \"; g__\" + silva_metadata[\"genus\"] +\n",
    "                              \"; s__\" + silva_metadata[\"species\"])\n",
    "tax_cols = ['taxonomy', 'superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "# Merge\n",
    "trait = pd.merge(trait, silva_metadata[[\"species_tax_id\"]+tax_cols], how=\"inner\", on=\"species_tax_id\")\n",
    "\n",
    "# Split\n",
    "out_dir = '../../data/cross_validation'\n",
    "for i in range(10):\n",
    "    ## Path\n",
    "    split_dir = os.path.join(out_dir, f\"split_{i}\")\n",
    "    ## ID of Reference seqs\n",
    "    ref_header_path = os.path.join(split_dir, \"nodeid_ref.txt\")\n",
    "    ref_header = []\n",
    "    with open(ref_header_path) as f:\n",
    "        for l in f.readlines():\n",
    "            ref_header.append(l.split()[0])\n",
    "    set_ref_header = set(ref_header)\n",
    "    ## Split the trait table\n",
    "    ref_trait_path = os.path.join(split_dir, \"traits_with_taxonomy.tsv\")\n",
    "    is_ref = trait[\"species_tax_id\"].apply(\n",
    "                 lambda x: x in ref_header)\n",
    "    trait[is_ref].to_csv(ref_trait_path, sep=\"\\t\", index=False)\n",
    "    # Taxonomy of reference seqs\n",
    "    ref_taxonomy_path = os.path.join(split_dir, \"ref_taxonomy.tsv\")\n",
    "    trait[is_ref][[\"species_tax_id\", \"taxonomy\"]].to_csv(ref_taxonomy_path, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "clades = [\"superkingdom\", \"phylum\", \"class\",\n",
    "          \"order\", \"family\", \"genus\", \"species\"]\n",
    "# Make reference dataset for taxonomy-based prediction\n",
    "for i in range(10):\n",
    "    split_dir = os.path.join(out_dir, f\"split_{i}\")\n",
    "    ref_trait_path = os.path.join(split_dir, \"traits_with_taxonomy.tsv\")\n",
    "    ref_trait = pd.read_csv(ref_trait_path, sep=\"\\t\")\n",
    "\n",
    "    # Calculate empirical distributions of reference traits\n",
    "    emp_trait = {}\n",
    "    for t in nt+ct:\n",
    "        emp = {}\n",
    "        ref_trait[t] = ref_trait[t].astype(float)\n",
    "        for c in clades:\n",
    "            cols = [c, t]\n",
    "            groupby = ref_trait[cols].groupby(c).mean()\n",
    "            groupby = groupby.reset_index()\n",
    "            groupby.fillna({t: \"NA\"}, inplace=True)\n",
    "            emp[c] = {groupby.loc[i, c]: groupby.loc[i, t]\n",
    "                        for i in range(groupby.shape[0])}\n",
    "        emp_trait[t] = emp\n",
    "    # Save\n",
    "    emp_file = open(os.path.join(split_dir, 'empirical_dict.json'), mode='w')\n",
    "    json.dump(emp_trait, emp_file, ensure_ascii=False)\n",
    "    emp_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "for i in $(seq 0 9); do qiime tools import --type 'FeatureData[Taxonomy]' --input-format HeaderlessTSVTaxonomyFormat --input-path ../../data/cross_validation/split_$i/ref_taxonomy.tsv --output-path ../../data/cross_validation/split_$i/ref_taxonomy.qza; done\n",
    "for i in $(seq 0 9); do qiime tools import --type 'FeatureData[Sequence]' --input-path ../../data/cross_validation/split_$i/ref_seq_full.fasta --output-path ../../data/cross_validation/split_$i/ref_seq_full.qza; done\n",
    "for i in $(seq 0 9); do qiime tools import --type 'FeatureData[Sequence]' --input-path ../../data/cross_validation/split_$i/test_seq_full.fasta --output-path ../../data/cross_validation/split_$i/test_seq_full.qza; done\n",
    "# Training naive bayes classifier\n",
    "for i in $(seq 0 9); do qiime feature-classifier fit-classifier-naive-bayes --i-reference-reads ../../data/cross_validation/split_$i/ref_seq_full.qza --i-reference-taxonomy ../../data/cross_validation/split_$i/ref_taxonomy.qza --o-classifier ../../data/cross_validation/split_$i/classifier.qza; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phylogeny-based prediction\n",
    "```sh\n",
    "for i in $(seq 0 9); do ./make_pro_ref.sh -t ../../data/ref_bac2feature/phylogeny/phylogeny.tre -a ../../data/ref_bac2feature/phylogeny/phylogeny.fasta -n ../../data/cross_validation/split_$i/nodeid_ref.txt -o ../../data/cross_validation/split_$i; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# Homology-based prediction\n",
    "for i in $(seq 0 9); do bac_to_feature.py -s ../../data/cross_validation/split_$i/test_seq_full.fasta -o ../../data/cross_validation/split_$i/estimation_blast.tsv -m homology --ref_blastdb ../../data/cross_validation/split_$i/blastdb/ref_seq_full --ref_table ../../data/cross_validation/split_$i/traits.tsv --threads 1; done\n",
    "\n",
    "# Taxonomy-based prediction\n",
    "for i in $(seq 0 9); do bac_to_feature.py -s ../../data/cross_validation/split_$i/test_seq_full.fasta -o ../../data/cross_validation/split_$i/estimation_blast.tsv -m taxonomy --ref_nb_classifier ../../data/cross_validation/split_$i/classifier.qza --ref_trait_taxonomy ../../data/cross_validation/split_$i/traits.tsv --threads 1; done\n",
    "\n",
    "# Phylogeny-based prediction\n",
    "for i in $(seq 0 9); do bac_to_feature.py -s ../../data/cross_validation/split_$i/test_seq_full.fasta -o ../../data/cross_validation/split_$i/estimation_full.tsv -m phylogeny --ref_dir ../../data/cross_validation/split_$i --ref_table ../../data/cross_validation/split_$i/traits.tsv --threads 1 --calculate_NSTI; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# Concatenate the prediction results\n",
    "head -n 1 ../../data/cross_validation/split_0/estimation_full.tsv > ../../data/cross_validation/estimation_picrust.tsv && ls ../../data/cross_validation/split_*/estimation_full.tsv | xargs -n 1 tail -n +2 >> ../../data/cross_validation/estimation_picrust.tsv\n",
    "\n",
    "head -n 1 ../../data/cross_validtion/split_0/estimation_blast.tsv > ../../data/cross_validation/estimation_blast.tsv && ls ../../data/cross_validation/split_*/estimation_blast.tsv | xargs -n 1 tail -n +2 >> ../../data/cross_validation/estimation_blast.tsv\n",
    "\n",
    "head -n 1 ../../data/cross_validation/split_0/estimation_naive.tsv > ../../data/cross_validation/estimation_naive.tsv && ls ../../data/cross_validation/split_*/estimation_naive.tsv | xargs -n 1 tail -n +2 >> ../../data/cross_validation/estimation_naive.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def get_pred_and_true_df(pred_vals_path, true_vals_path):\n",
    "    # Prediction\n",
    "    pred_vals = pd.read_csv(pred_vals_path, sep=\"\\t\")\n",
    "    pred_vals[\"sequence\"] = pred_vals[\"sequence\"].astype(str)\n",
    "    # Reference\n",
    "    true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "    cmp = pd.merge(pred_vals, true_vals,\n",
    "                   left_on='sequence', right_on=\"species_tax_id\", how='inner', suffixes=['_e', '_t'])\n",
    "    return cmp\n",
    "\n",
    "def remove_null_values(cmp, t, dtype):\n",
    "    known_flag = (~cmp[t+'_t'].isnull()) & (~cmp[t+'_e'].isnull())\n",
    "    pred_vals, true_vals = cmp[known_flag][t+'_e'], cmp[known_flag][t+'_t']\n",
    "    if dtype == 'float':\n",
    "        pred_vals = pred_vals.astype(float)\n",
    "        true_vals = true_vals.astype(float)\n",
    "    elif dtype == 'int':\n",
    "        pred_vals = pred_vals.astype(int)\n",
    "        true_vals = true_vals.astype(int)\n",
    "    return pred_vals, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals_path = \"../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Continuous traits\n",
    "for i in range(0, 10):\n",
    "    # Homology\n",
    "    homology_result_path = f\"../../data/cross_validation/split_{i}/estimation_blast.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=homology_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_homology = []\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_homology += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # Taxonomy\n",
    "    taxonomy_result_path = f\"../../data/cross_validation/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=taxonomy_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_taxonomy = []\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_taxonomy += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # Phylogeny\n",
    "    phylogeny_result_path = f\"../../data/cross_validation/split_{i}/estimation_full.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=phylogeny_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_phylogeny = []\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_phylogeny += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": nt,\n",
    "                        \"homology\": res_list_homology,\n",
    "                        \"taxonomy\": res_list_taxonomy,\n",
    "                        \"phylogeny\": res_list_phylogeny})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_nt = tmp\n",
    "    else:\n",
    "        res_all_nt = pd.concat([res_all_nt, tmp], axis=0)\n",
    "\n",
    "res_all_melt_nt = res_all_nt.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical traits\n",
    "metric = 'corr'\n",
    "def calc_accuracy(pred_vals, true_vals, metric):\n",
    "    if metric == 'f1_score':\n",
    "        result = f1_score(y_pred=pred_vals, y_true=true_vals, average='macro')\n",
    "    elif metric == 'precision':\n",
    "        result = precision_score(y_pred=pred_vals, y_true=true_vals, average='macro', zero_division=0)\n",
    "    elif metric == 'recall':\n",
    "        result = recall_score(y_pred=pred_vals, y_true=true_vals, average='macro')\n",
    "    elif metric == 'corr':\n",
    "        result = pred_vals.corr(true_vals, method=\"pearson\")\n",
    "    return result\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # Homology\n",
    "    homology_result_path = f\"../../data/cross_validation/split_{i}/estimation_blast.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=homology_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_homology = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_homology += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Taxonomy\n",
    "    taxonomy_result_path = f\"../../data/cross_validation/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=taxonomy_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_taxonomy = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_taxonomy += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Phylogeny\n",
    "    phylogeny_result_path = f\"../../data/cross_validation/split_{i}/estimation_full.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=phylogeny_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_phylogeny = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_phylogeny += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": ct,\n",
    "                        \"homology\": res_list_homology,\n",
    "                        \"taxonomy\": res_list_taxonomy,\n",
    "                        \"phylogeny\": res_list_phylogeny})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_ct = tmp\n",
    "    else:\n",
    "        res_all_ct = pd.concat([res_all_ct, tmp], axis=0)\n",
    "\n",
    "res_all_melt_ct = res_all_ct.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def calc_wilcoxon_signed(res_all_melt, t):\n",
    "    res_trait = res_all_melt[res_all_melt['trait'] == t]\n",
    "    y1 = res_trait[res_trait['method']=='homology']['accuracy']\n",
    "    y2 = res_trait[res_trait['method']=='taxonomy']['accuracy']\n",
    "    y3 = res_trait[res_trait['method']=='phylogeny']['accuracy']\n",
    "    p1 = wilcoxon(y1, y2, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    p2 = wilcoxon(y2, y3, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    p3 = wilcoxon(y1, y3, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    return p1, p2, p3\n",
    "\n",
    "def prep_accuracy_and_trait_list(res_all_melt):\n",
    "    groupby = res_all_melt[['trait', 'accuracy']].groupby('trait').mean()\n",
    "    groupby.reset_index(inplace=True)\n",
    "    groupby.sort_values(by='accuracy', ascending=True, inplace=True)\n",
    "    trait_list = list(groupby['trait'])\n",
    "\n",
    "    acc_list = []\n",
    "    for t in trait_list:\n",
    "        for method in ['homology', 'taxonomy', 'phylogeny']:\n",
    "            res_trait = res_all_melt[(res_all_melt['trait'] == t) & (res_all_melt['method'] == method)]\n",
    "            acc_list += [list(res_trait['accuracy'].fillna(0))] # replace nan to 0\n",
    "        acc_list += [[]]\n",
    "    return acc_list, trait_list\n",
    "\n",
    "def plot_accuracy_boxplot(acc_list, trait_list, ax):\n",
    "    bplot = ax.boxplot(list(reversed(acc_list)),\n",
    "                       widths=0.7,\n",
    "                       vert=False,\n",
    "                       showfliers=False,\n",
    "                       patch_artist=True,\n",
    "                       boxprops=dict(color='black', linewidth=0.8),\n",
    "                       whiskerprops=dict(color='black', linewidth=0.8)\n",
    "                       )\n",
    "\n",
    "    boxes = bplot['boxes']\n",
    "    colors = cmap2.colors[:4] * int(len(boxes) / 4)\n",
    "    for patch, color in zip(boxes, list(reversed(colors))):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    ax.set_xlim(-0.03, 1)\n",
    "    ax.set_ylim(0, len(acc_list)+1)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(0.2))\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "    ax.grid(axis='x', alpha=0.1, color='grey')\n",
    "    ax.grid(axis='y', alpha=0.1, color='grey')\n",
    "\n",
    "    label_position = 3\n",
    "    ax.set_yticks(np.arange(start=label_position, stop=len(acc_list)+label_position, step=4))\n",
    "    ax.set_yticklabels(list(reversed([titles[t] for t in trait_list])))\n",
    "\n",
    "    ax.spines['top'].set(alpha=0.1, color='grey')\n",
    "    ax.spines['right'].set(alpha=0.1, color='grey')\n",
    "\n",
    "    ax.legend(list(reversed(boxes[-3:])),\n",
    "              ['Homology-based', 'Taxonomy-based', 'Phylogeny-based'],\n",
    "              edgecolor=(0.9, 0.9, 0.9), facecolor='white',\n",
    "              bbox_to_anchor=(0., 0.), loc='lower left')\n",
    "    return\n",
    "\n",
    "def calc_rank(res_all_melt, trait_list):\n",
    "    med_df = res_all_melt.groupby(['trait', 'method']).median()\n",
    "    med_df.reset_index(inplace=True)\n",
    "\n",
    "    med_df.sort_values(by=['trait', 'accuracy'], ascending=False, inplace=True)\n",
    "    med_df['rank'] = [1, 2, 3] * len(med_df['trait'].unique())\n",
    "\n",
    "    rows = trait_list\n",
    "    cols = ['homology', 'taxonomy', 'phylogeny']\n",
    "\n",
    "    heatmap_vals = np.zeros([len(rows), len(cols)])\n",
    "    heatmap_df = pd.DataFrame(heatmap_vals, index=rows, columns=cols)\n",
    "\n",
    "    def get_rank_val(med_df, trait, method):\n",
    "        # Extract\n",
    "        focal_df = med_df[(med_df['trait']==trait) & (med_df['method']==method)]\n",
    "        # Convert datatype\n",
    "        res = int(focal_df['rank'])\n",
    "        return res\n",
    "\n",
    "    for r in rows:\n",
    "        for c in cols:\n",
    "            heatmap_df.loc[r, c] = get_rank_val(med_df, r, c)\n",
    "    return heatmap_df\n",
    "\n",
    "def stat_rank(rank, pvals): # modifying the rank based on the p-values\n",
    "    # pvals[0]: homology vs taxonomy, pvals[1]: taxonomy vs phylogeny, pvals[2]: homology vs phylogeny\n",
    "    if rank == [1, 2, 3]:\n",
    "        if np.sum(pvals)==3: # If there is statistical difference between the all three methods, the rank is the same.\n",
    "            res = [1, 2, 3]\n",
    "        elif pvals[0] and pvals[1]: # This case is not possible because pvals[2] should also be True.\n",
    "            raise(ValueError)\n",
    "        elif pvals[1] and pvals[2]: # homology, phylogeny: 1st-tied, taxonomy: 3rd\n",
    "            res = [1, 1, 3]\n",
    "        elif pvals[0] and pvals[2]: # homology: 1st, taxonomy, phylogeny: 2nd-tied\n",
    "            res = [1, 2, 2]\n",
    "        else: # If statistical difference is detected only between two methods, the rank cannot be determined\n",
    "            res = [0, 0, 0]\n",
    "    if rank == [2, 1, 3]:\n",
    "        if np.sum(pvals)==3:\n",
    "            res = [2, 1, 3]\n",
    "        elif pvals[0] and pvals[1]:\n",
    "            res = [2, 1, 2]\n",
    "        elif pvals[1] and pvals[2]:\n",
    "            res = [1, 1, 3]\n",
    "        elif pvals[0] and pvals[2]:\n",
    "            raise(ValueError)\n",
    "        else:\n",
    "            res = [0, 0, 0]\n",
    "    if rank == [3, 2, 1]:\n",
    "        if np.sum(pvals)==3:\n",
    "            res = [3, 2, 1]\n",
    "        elif pvals[0] and pvals[1]:\n",
    "            raise(ValueError)\n",
    "        elif pvals[1] and pvals[2]:\n",
    "            res = [2, 2, 1]\n",
    "        elif pvals[0] and pvals[2]:\n",
    "            res = [3, 1, 1]\n",
    "        else:\n",
    "            res = [0, 0, 0]\n",
    "    if rank == [1, 3, 2]:\n",
    "        if np.sum(pvals) == 3:\n",
    "            res = [1, 3, 2]\n",
    "        elif pvals[0] and pvals[1]:\n",
    "            res = [1, 3, 1]\n",
    "        elif pvals[1] and pvals[2]:\n",
    "            raise(ValueError)\n",
    "        elif pvals[0] and pvals[2]:\n",
    "            res = [1, 2, 2]\n",
    "        else:\n",
    "            res = [0, 0, 0]\n",
    "    if rank == [2, 3, 1]:\n",
    "        if np.sum(pvals) == 3:\n",
    "            res = [2, 3, 1]\n",
    "        elif pvals[0] and pvals[1]:\n",
    "            res = [1, 3, 1]\n",
    "        elif pvals[1] and pvals[2]:\n",
    "            res = [2, 2, 1]\n",
    "        elif pvals[0] and pvals[2]:\n",
    "            raise(ValueError)\n",
    "        else:\n",
    "            res = [0, 0, 0]\n",
    "    if rank == [3, 1, 2]:\n",
    "        if np.sum(pvals) == 3:\n",
    "            res = [3, 1, 2]\n",
    "        elif pvals[0] and pvals[1]:\n",
    "            res = [2, 1, 2]\n",
    "        elif pvals[1] and pvals[2]:\n",
    "            raise(ValueError)\n",
    "        elif pvals[0] and pvals[2]:\n",
    "            res = [3, 1, 1]\n",
    "        else:\n",
    "            res = [0, 0, 0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(4, 9))\n",
    "gs_master = GridSpec(nrows=2, ncols=2, height_ratios=[11, 16], width_ratios=[1, 0.2], hspace=0.35, wspace=0.1)\n",
    "\n",
    "### Boxplot: continuous traits\n",
    "gs_1 = GridSpecFromSubplotSpec(nrows=1, ncols=1, subplot_spec=gs_master[0, 0])\n",
    "axes_1 = figure.add_subplot(gs_1[:, :])\n",
    "\n",
    "# Accuracy and Trait list of 10-fold cross validation\n",
    "acc_list, trait_list = prep_accuracy_and_trait_list(res_all_melt=res_all_melt_nt)\n",
    "\n",
    "# Plot\n",
    "plot_accuracy_boxplot(acc_list=acc_list, trait_list=trait_list, ax=axes_1)\n",
    "axes_1.set_title('11 continuous traits', fontsize=10)\n",
    "axes_1.set_xlabel('Prediction accuracy\\n(Pearson Correlation Coefficient)')\n",
    "\n",
    "### Heatplot: continuous traits\n",
    "gs_2 = GridSpecFromSubplotSpec(nrows=1, ncols=1, subplot_spec=gs_master[0, 1])\n",
    "axes_2 = figure.add_subplot(gs_2[:, :])\n",
    "\n",
    "heatmap_df_nt = calc_rank(res_all_melt=res_all_melt_nt, trait_list=trait_list)\n",
    "\n",
    "# Friedman test (all traits)\n",
    "list_p_value_friedman = []\n",
    "for i in np.arange(start=0, stop=len(acc_list), step=4):\n",
    "    f_stat, p_value = friedmanchisquare(acc_list[i], acc_list[i+1], acc_list[i+2])\n",
    "    list_p_value_friedman += [p_value]\n",
    "res_mptest_friedman = multipletests(pvals=list_p_value_friedman, alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "# Wilcoxon signed-rank test (positive traits)\n",
    "list_p_value_wilcoxon = []\n",
    "modified_trait_list = []\n",
    "for i, t in enumerate(res_mptest_friedman[0]):\n",
    "    if t:\n",
    "        list_p_value_wilcoxon += [calc_wilcoxon_signed(res_all_melt_nt, trait_list[i])]\n",
    "        modified_trait_list += [trait_list[i]]\n",
    "res_mptest_wilcoxon = multipletests(pvals=[pv for p in list_p_value_wilcoxon for pv in p], alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "i = 0\n",
    "mp_pvals = []\n",
    "for t in trait_list:\n",
    "    if t in set(modified_trait_list):\n",
    "        mp_pvals += [[res_mptest_wilcoxon[0][3*i+j] for j in [0, 1, 2]]]\n",
    "        i += 1\n",
    "    else:\n",
    "        mp_pvals += [None]\n",
    "\n",
    "for i, t in enumerate(trait_list):\n",
    "    rank = list(heatmap_df_nt.loc[t, :])\n",
    "    pvals = mp_pvals[i]\n",
    "    if pvals is not None:\n",
    "        heatmap_df_nt.loc[t, :] = stat_rank(rank, pvals)\n",
    "    else:\n",
    "        heatmap_df_nt.loc[t, :] = [3, 3, 3]\n",
    "\n",
    "sns.heatmap(heatmap_df_nt, cmap=['#F2B379', '#F8DAAC', '#FFF5EB'],\n",
    "            square=False, vmax=3, vmin=1, cbar=False, annot=True, xticklabels=1, yticklabels=1, linewidths=.5, ax=axes_2)\n",
    "axes_2.set_xticklabels(['H', 'T', 'P'], rotation=0)\n",
    "axes_2.set_xlabel('Prediction \\nMethod')\n",
    "axes_2.set_yticklabels([])\n",
    "axes_2.set_title('Rank', fontsize=10)\n",
    "axes_2.tick_params(left=False)\n",
    "\n",
    "### Boxplot: categorical traits\n",
    "gs_3 = GridSpecFromSubplotSpec(nrows=1, ncols=1, subplot_spec=gs_master[1, 0])\n",
    "axes_3 = figure.add_subplot(gs_3[:, :])\n",
    "\n",
    "acc_list, trait_list = prep_accuracy_and_trait_list(res_all_melt=res_all_melt_ct)\n",
    "# Plot\n",
    "plot_accuracy_boxplot(acc_list=acc_list, trait_list=trait_list, ax=axes_3)\n",
    "axes_3.set_title('16 categorical traits', fontsize=10)\n",
    "axes_3.set_xlabel('Prediction accuracy\\n(Matthews Correlation Coefficient)')\n",
    "\n",
    "### Heatmap: categorical traits\n",
    "gs_4 = GridSpecFromSubplotSpec(nrows=1, ncols=1, subplot_spec=gs_master[1, 1])\n",
    "axes_4 = figure.add_subplot(gs_4[:, :])\n",
    "\n",
    "heatmap_df_ct = calc_rank(res_all_melt=res_all_melt_ct, trait_list=trait_list)\n",
    "\n",
    "# Friedman test (all traits)\n",
    "list_p_value_friedman = []\n",
    "for i in np.arange(start=0, stop=len(acc_list), step=4):\n",
    "    f_stat, p_value = friedmanchisquare(acc_list[i], acc_list[i+1], acc_list[i+2])\n",
    "    list_p_value_friedman += [p_value]\n",
    "res_mptest_friedman = multipletests(pvals=list_p_value_friedman, alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "# Wilcoxon signed-rank test (positive traits)\n",
    "list_p_value_wilcoxon = []\n",
    "modified_trait_list = []\n",
    "for i, t in enumerate(res_mptest_friedman[0]):\n",
    "    if t:\n",
    "        list_p_value_wilcoxon += [calc_wilcoxon_signed(res_all_melt_ct, trait_list[i])]\n",
    "        modified_trait_list += [trait_list[i]]\n",
    "res_mptest_wilcoxon = multipletests(pvals=[pv for p in list_p_value_wilcoxon for pv in p], alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "i = 0\n",
    "mp_pvals = []\n",
    "for t in trait_list:\n",
    "    if t in set(modified_trait_list):\n",
    "        mp_pvals += [[res_mptest_wilcoxon[0][3*i+j] for j in [0, 1, 2]]]\n",
    "        i += 1\n",
    "    else:\n",
    "        mp_pvals += [None]\n",
    "\n",
    "for i, t in enumerate(trait_list):\n",
    "    rank = list(heatmap_df_ct.loc[t, :])\n",
    "    pvals = mp_pvals[i]\n",
    "    if pvals is not None:\n",
    "        heatmap_df_ct.loc[t, :] = stat_rank(rank, pvals)\n",
    "    else:\n",
    "        heatmap_df_ct.loc[t, :] = [3, 3, 3]\n",
    "\n",
    "sns.heatmap(heatmap_df_ct, cmap=['#F2B379', '#F8DAAC', '#FFF5EB'],\n",
    "            square=False, vmax=3, vmin=1, cbar=False, annot=True, xticklabels=1, yticklabels=1, linewidths=.5, ax=axes_4)\n",
    "\n",
    "axes_4.set_xticklabels(['H', 'T', 'P'], rotation=0)\n",
    "axes_4.set_xlabel('Prediction \\nMethod')\n",
    "axes_4.set_yticklabels([])\n",
    "axes_4.set_title('Rank', fontsize=10)\n",
    "axes_4.tick_params(left=False)\n",
    "\n",
    "plt.savefig(\"../../results/03_cross_validation/fig2a-2b.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "metric = 'precision'\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # Homology\n",
    "    homology_result_path = f\"../../data/cross_validation/split_{i}/estimation_blast.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=homology_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_homology = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_homology += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Taxonomy\n",
    "    taxonomy_result_path = f\"../../data/cross_validation/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=taxonomy_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_taxonomy = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_taxonomy += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Phylogeny\n",
    "    phylogeny_result_path = f\"../../data/cross_validation/split_{i}/estimation_full.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=phylogeny_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_phylogeny = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_phylogeny += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": ct,\n",
    "                        \"homology\": res_list_homology,\n",
    "                        \"taxonomy\": res_list_taxonomy,\n",
    "                        \"phylogeny\": res_list_phylogeny})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_ct = tmp\n",
    "    else:\n",
    "        res_all_ct = pd.concat([res_all_ct, tmp], axis=0)\n",
    "\n",
    "res_all_melt_ct = res_all_ct.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4, 5), width_ratios=[1, 0.3])\n",
    "\n",
    "### Boxplot: categorical traits\n",
    "axes_3 = axes[0]\n",
    "\n",
    "acc_list, trait_list = prep_accuracy_and_trait_list(res_all_melt=res_all_melt_ct)\n",
    "# Plot\n",
    "plot_accuracy_boxplot(acc_list=acc_list, trait_list=trait_list, ax=axes_3)\n",
    "axes_3.set_title('16 categorical traits', fontsize=10)\n",
    "axes_3.set_xlabel('Prediction accuracy\\n(Precision)')\n",
    "\n",
    "### Heatmap: categorical traits\n",
    "axes_4 = axes[1]\n",
    "\n",
    "heatmap_df_ct = calc_rank(res_all_melt=res_all_melt_ct, trait_list=trait_list)\n",
    "\n",
    "# Friedman test (all traits)\n",
    "list_p_value_friedman = []\n",
    "for i in np.arange(start=0, stop=len(acc_list), step=4):\n",
    "    f_stat, p_value = friedmanchisquare(acc_list[i], acc_list[i+1], acc_list[i+2])\n",
    "    list_p_value_friedman += [p_value]\n",
    "res_mptest_friedman = multipletests(pvals=list_p_value_friedman, alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "# Wilcoxon signed-rank test (positive traits)\n",
    "list_p_value_wilcoxon = []\n",
    "modified_trait_list = []\n",
    "for i, t in enumerate(res_mptest_friedman[0]):\n",
    "    if t:\n",
    "        list_p_value_wilcoxon += [calc_wilcoxon_signed(res_all_melt_ct, trait_list[i])]\n",
    "        modified_trait_list += [trait_list[i]]\n",
    "res_mptest_wilcoxon = multipletests(pvals=[pv for p in list_p_value_wilcoxon for pv in p], alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "i = 0\n",
    "mp_pvals = []\n",
    "for t in trait_list:\n",
    "    if t in set(modified_trait_list):\n",
    "        mp_pvals += [[res_mptest_wilcoxon[0][3*i+j] for j in [0, 1, 2]]]\n",
    "        i += 1\n",
    "    else:\n",
    "        mp_pvals += [None]\n",
    "\n",
    "for i, t in enumerate(trait_list):\n",
    "    rank = list(heatmap_df_ct.loc[t, :])\n",
    "    pvals = mp_pvals[i]\n",
    "    if pvals is not None:\n",
    "        heatmap_df_ct.loc[t, :] = stat_rank(rank, pvals)\n",
    "    else:\n",
    "        heatmap_df_ct.loc[t, :] = [3, 3, 3]\n",
    "\n",
    "sns.heatmap(heatmap_df_ct, cmap=['#F2B379', '#F8DAAC', '#FFF5EB'],\n",
    "            square=False, vmax=3, vmin=1, cbar=False, annot=True, xticklabels=1, yticklabels=1, linewidths=.5, ax=axes_4)\n",
    "\n",
    "axes_4.set_xticklabels(['H', 'T', 'P'], rotation=0)\n",
    "axes_4.set_xlabel('Prediction \\nMethod')\n",
    "axes_4.set_yticklabels([])\n",
    "axes_4.set_title('Rank', fontsize=10)\n",
    "axes_4.tick_params(left=False)\n",
    "\n",
    "plt.savefig(\"../../results/03_cross_validation/figS2a.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "metric = 'recall'\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # Homology\n",
    "    homology_result_path = f\"../../data/cross_validation/split_{i}/estimation_blast.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=homology_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_homology = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_homology += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Taxonomy\n",
    "    taxonomy_result_path = f\"../../data/cross_validation/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=taxonomy_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_taxonomy = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_taxonomy += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Phylogeny\n",
    "    phylogeny_result_path = f\"../../data/cross_validation/split_{i}/estimation_full.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=phylogeny_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_phylogeny = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='int')\n",
    "        res_list_phylogeny += [calc_accuracy(pred_vals, true_vals, metric)]\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": ct,\n",
    "                        \"homology\": res_list_homology,\n",
    "                        \"taxonomy\": res_list_taxonomy,\n",
    "                        \"phylogeny\": res_list_phylogeny})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_ct = tmp\n",
    "    else:\n",
    "        res_all_ct = pd.concat([res_all_ct, tmp], axis=0)\n",
    "\n",
    "res_all_melt_ct = res_all_ct.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4, 5), width_ratios=[1, 0.3])\n",
    "\n",
    "### Boxplot: categorical traits\n",
    "axes_3 = axes[0]\n",
    "\n",
    "acc_list, trait_list = prep_accuracy_and_trait_list(res_all_melt=res_all_melt_ct)\n",
    "# Plot\n",
    "plot_accuracy_boxplot(acc_list=acc_list, trait_list=trait_list, ax=axes_3)\n",
    "axes_3.set_title('16 categorical traits', fontsize=10)\n",
    "axes_3.set_xlabel('Prediction accuracy\\n(Recall)')\n",
    "\n",
    "### Heatmap: categorical traits\n",
    "axes_4 = axes[1]\n",
    "\n",
    "heatmap_df_ct = calc_rank(res_all_melt=res_all_melt_ct, trait_list=trait_list)\n",
    "\n",
    "# Friedman test (all traits)\n",
    "list_p_value_friedman = []\n",
    "for i in np.arange(start=0, stop=len(acc_list), step=4):\n",
    "    f_stat, p_value = friedmanchisquare(acc_list[i], acc_list[i+1], acc_list[i+2])\n",
    "    list_p_value_friedman += [p_value]\n",
    "res_mptest_friedman = multipletests(pvals=list_p_value_friedman, alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "# Wilcoxon signed-rank test (positive traits)\n",
    "list_p_value_wilcoxon = []\n",
    "modified_trait_list = []\n",
    "for i, t in enumerate(res_mptest_friedman[0]):\n",
    "    if t:\n",
    "        list_p_value_wilcoxon += [calc_wilcoxon_signed(res_all_melt_ct, trait_list[i])]\n",
    "        modified_trait_list += [trait_list[i]]\n",
    "res_mptest_wilcoxon = multipletests(pvals=[pv for p in list_p_value_wilcoxon for pv in p], alpha=0.05, method=\"fdr_bh\")\n",
    "\n",
    "i = 0\n",
    "mp_pvals = []\n",
    "for t in trait_list:\n",
    "    if t in set(modified_trait_list):\n",
    "        mp_pvals += [[res_mptest_wilcoxon[0][3*i+j] for j in [0, 1, 2]]]\n",
    "        i += 1\n",
    "    else:\n",
    "        mp_pvals += [None]\n",
    "\n",
    "for i, t in enumerate(trait_list):\n",
    "    rank = list(heatmap_df_ct.loc[t, :])\n",
    "    pvals = mp_pvals[i]\n",
    "    if pvals is not None:\n",
    "        heatmap_df_ct.loc[t, :] = stat_rank(rank, pvals)\n",
    "    else:\n",
    "        heatmap_df_ct.loc[t, :] = [3, 3, 3]\n",
    "\n",
    "sns.heatmap(heatmap_df_ct, cmap=['#F2B379', '#F8DAAC', '#FFF5EB'],\n",
    "            square=False, vmax=3, vmin=1, cbar=False, annot=True, xticklabels=1, yticklabels=1, linewidths=.5, ax=axes_4)\n",
    "\n",
    "axes_4.set_xticklabels(['H', 'T', 'P'], rotation=0)\n",
    "axes_4.set_xlabel('Prediction \\nMethod')\n",
    "axes_4.set_yticklabels([])\n",
    "axes_4.set_title('Rank', fontsize=10)\n",
    "axes_4.tick_params(left=False)\n",
    "\n",
    "plt.savefig(\"../../results/03_cross_validation/figS2b.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation using variabe regions of 16S rRNA gene sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing cross-validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = '../../data/cross_validation_vr'\n",
    "split_dirs = [join(data_dir, f'split_{i}') for i in range(10)]\n",
    "for split_dir in split_dirs:\n",
    "    if not os.path.exists(split_dir):\n",
    "        os.makedirs(split_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "for i in $(seq 0 9); do cp ../../data/cross_validation/split_$i/nodeid_test.txt ../../data/cross_validation_vr/split_$i; cp ../../data/cross_validation/split_$i/nodeid_ref.txt ../../data/cross_validation_vr/split_$i; cp ../../data/cross_validation/split_$i/traits.tsv ../../data/cross_validation_vr/split_$i; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting variable regions from SSU sequences\n",
    "#### Import\n",
    "```sh\n",
    "cp ../../data/intermediate_dir/SILVA_138.1_SSURef_NR99_tax_silva_taxid.fasta ../../data/cross_validation_vr/silva_seq.fasta\n",
    "qiime tools import --type 'FeatureData[Sequence]' --input-path ../../data/cross_validation_vr/silva_seq.fasta --output-path ../../data/cross_validation_vr/silva_seq.qza\n",
    "# For sequences that do not contain the 27F primer, use the sequence from the beginning to the reverse primer. Attach a pseudo-primer to the beginning.\n",
    "seqkit mutate -i 0:ACGTACGTACGTACGTACGT --quiet ../../data/cross_validation_vr/silva_seq.fasta > ../../data/cross_validation_vr/silva_seq_w_primer.fasta\n",
    "qiime tools import --type 'FeatureData[Sequence]' --input-path ../../data/cross_validation_vr/silva_seq_w_primer.fasta --output-path ../../data/cross_validation_vr/silva_seq_w_primer.qza\n",
    "```\n",
    "#### V1-V2: 27F-337R\n",
    "```sh\n",
    "qiime feature-classifier extract-reads --i-sequences ../../data/cross_validation_vr/silva_seq.qza --p-f-primer AGAGTTTGATCMTGGCTCAG --p-r-primer CTGCWGCCTCCCGTAGGAGTC --p-min-length 200 --p-max-length 400 --o-reads ../../data/cross_validation_vr/silva_seq_27F_337R.qza\n",
    "qiime tools export --input-path ../../data/cross_validation_vr/silva_seq_27F_337R.qza --output-path ../../data/cross_validation_vr/qiime_output\n",
    "cp ../../data/cross_validation_vr/qiime_output/dna-sequences.fasta ../../data/cross_validation_vr/silva_seq_27F_337R.fasta\n",
    "# For sequences that do not contain the 27F primer, use the sequence from the beginning to the 337R primer.\n",
    "qiime feature-classifier extract-reads --i-sequences ../../data/cross_validation_vr/silva_seq_w_primer.qza --p-f-primer ACGTACGTACGTACGTACGT --p-r-primer CTGCWGCCTCCCGTAGGAGTC --o-reads ../../data/cross_validation_vr/silva_seq_337R.qza\n",
    "qiime tools export --input-path ../../data/cross_validation_vr/silva_seq_337R.qza --output-path ../../data/cross_validation_vr/qiime_output/\n",
    "cp ../../data/cross_validation_vr/qiime_output/dna-sequences.fasta ../../data/cross_validation_vr/silva_seq_337R.fasta\n",
    "seqkit seq -n ../../data/cross_validation_vr/silva_seq_27F_337R.fasta > ../../data/cross_validation_vr/silva_seq_27F_337R.txt\n",
    "seqkit grep -vnf ../../data/cross_validation_vr/silva_seq_27F_337R.txt ../../data/cross_validation_vr/silva_seq_337R.fasta > ../../data/cross_validation_vr/silva_seq_wo27F_337R.fasta\n",
    "cat ../../data/cross_validation_vr/silva_seq_27F_337R.fasta ../../data/cross_validation_vr/silva_seq_wo27F_337R.fasta > ../../data/cross_validation_vr/silva_seq_wwo27F_337R.fasta\n",
    "```\n",
    "#### V3: 337F-518R\n",
    "```sh\n",
    "qiime feature-classifier extract-reads --i-sequences ../../data/cross_validation_vr/silva_seq.qza --p-f-primer GACTCCTACGGGAGGCWGCAG --p-r-primer CGTATTACCGCGGCTGCTGG --p-min-length 100 --p-max-length 300 --o-reads ../../data/cross_validation_vr/silva_seq_337F_518R.qza\n",
    "qiime tools export --input-path ../../data/cross_validation_vr/silva_seq_337F_518R.qza --output-path ../../data/cross_validation_vr/qiime_output\n",
    "cp ../../data/cross_validation_vr/qiime_output/dna-sequences.fasta ../../data/cross_validation_vr/silva_seq_337F_518R.fasta\n",
    "```\n",
    "#### V4: 518F-800R\n",
    "```sh\n",
    "qiime feature-classifier extract-reads --i-sequences ../../data/cross_validation_vr/silva_seq.qza --p-f-primer CCAGCAGCCGCGGTAATACG --p-r-primer TACCAGGGTATCTAATCC --p-min-length 200 --p-max-length 400 --o-reads ../../data/cross_validation_vr/silva_seq_518F_800R.qza\n",
    "qiime tools export --input-path ../../data/cross_validation_vr/silva_seq_518F_800R.qza --output-path ../../data/cross_validation_vr/qiime_output\n",
    "cp ../../data/cross_validation_vr/qiime_output/dna-sequences.fasta ../../data/cross_validation_vr/silva_seq_518F_800R.fasta\n",
    "```\n",
    "### V1-V3: 27F-518R\n",
    "```sh\n",
    "qiime feature-classifier extract-reads --i-sequences ../../data/cross_validation_vr/silva_seq.qza --p-f-primer AGAGTTTGATCMTGGCTCAG --p-r-primer CGTATTACCGCGGCTGCTGG --p-min-length 400 --p-max-length 600 --o-reads ../../data/cross_validation_vr/silva_seq_27F_518R.qza\n",
    "qiime tools export --input-path ../../data/cross_validation_vr/silva_seq_27F_518R.qza --output-path ../../data/cross_validation_vr/qiime_output\n",
    "cp ../../data/cross_validation_vr/qiime_output/dna-sequences.fasta ../../data/cross_validation_vr/silva_seq_27F_518R.fasta\n",
    "# For sequences that do not contain the 27F primer, use the sequence from the beginning to the 508R primer.\n",
    "qiime feature-classifier extract-reads --i-sequences ../../data/cross_validation_vr/silva_seq_w_primer.qza --p-f-primer ACGTACGTACGTACGTACGT --p-r-primer CGTATTACCGCGGCTGCTGG --o-reads ../../data/cross_validation_vr/silva_seq_518R.qza\n",
    "qiime tools export --input-path ../../data/cross_validation_vr/silva_seq_518R.qza --output-path ../../data/cross_validation_vr/qiime_output\n",
    "cp ../../data/cross_validation_vr/qiime_output/dna-sequences.fasta ../../data/cross_validation_vr/silva_seq_518R.fasta\n",
    "seqkit seq -n ../../data/cross_validation_vr/silva_seq_27F_518R.fasta > ../../data/cross_validation_vr/silva_seq_27F_518R.txt\n",
    "seqkit grep -vnf ../../data/cross_validation_vr/silva_seq_27F_518R.txt ../../data/cross_validation_vr/silva_seq_518R.fasta > ../../data/cross_validation_vr/silva_seq_wo27F_518R.fasta\n",
    "cat ../../data/cross_validation_vr/silva_seq_27F_518R.fasta ../../data/cross_validation_vr/silva_seq_wo27F_518R.fasta > ../../data/cross_validation_vr/silva_seq_wwo27F_518R.fasta\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phylogeny-based prediction\n",
    "```sh\n",
    "# Constructing reference dataset for phylogeny-based prediction\n",
    "for i in $(seq 0 9); do make_pro_ref.sh -t ../../data/ref_bac2feature/phylogeny/phylogeny.tre -a ../../data/ref_bac2feature/phylogeny/phylogeny.fasta -n ../../data/cross_validation_vr/split_$i/nodeid_ref.txt -o ../../data/cross_validation_vr/split_$i; done\n",
    "# Constructing test 16S rRNA gene sequences\n",
    "for i in $(seq 0 9); \n",
    "do seqkit grep -nf ../../data/cross_validation_vr/split_$i/nodeid_test.txt ../../data/cross_validation_vr/silva_seq.fasta > ../../data/cross_validation_vr/split_$i/test_seq_full.fasta; \n",
    "seqkit grep -nf ../../data/cross_validation_vr/split_$i/nodeid_test.txt ../../data/cross_validation_vr/silva_seq_wwo27F_337R.fasta > ../../data/cross_validation_vr/split_$i/test_seq_wwo27F_337R.fasta; \n",
    "seqkit grep -nf ../../data/cross_validation_vr/split_$i/nodeid_test.txt ../../data/cross_validation_vr/silva_seq_wwo27F_518R.fasta > ../../data/cross_validation_vr/split_$i/test_seq_wwo27F_518R.fasta; \n",
    "seqkit grep -nf ../../data/cross_validation_vr/split_$i/nodeid_test.txt ../../data/cross_validation_vr/silva_seq_337F_518R.fasta > ../../data/cross_validation_vr/split_$i/test_seq_337F_518R.fasta; \n",
    "seqkit grep -nf ../../data/cross_validation_vr/split_$i/nodeid_test.txt ../../data/cross_validation_vr/silva_seq_518F_800R.fasta > ../../data/cross_validation_vr/split_$i/test_seq_518F_800R.fasta; \n",
    "done\n",
    "# Concatenate the prediction results\n",
    "for i in $(seq 0 9); do echo ../../data/cross_validation_vr/split_$i/estimation_full.tsv; done | xargs cat > ../../data/cross_validation_vr/estimation_full.tsv\n",
    "for i in $(seq 0 9); do echo ../../data/cross_validation_vr/split_$i/estimation_wwo27F_337R.tsv; done | xargs cat > ../../data/cross_validation_vr/estimation_wwo27F_337R.tsv\n",
    "for i in $(seq 0 9); do echo ../../data/cross_validation_vr/split_$i/estimation_337F_518R.tsv; done | xargs cat > ../../data/cross_validation_vr/estimation_337F_518R.tsv\n",
    "for i in $(seq 0 9); do echo ../../data/cross_validation_vr/split_$i/estimation_518F_800R.tsv; done | xargs cat > ../../data/cross_validation_vr/estimation_518F_800R.tsv\n",
    "for i in $(seq 0 9); do echo ../../data/cross_validation_vr/split_$i/estimation_wwo27F_518R.tsv; done | xargs cat > ../../data/cross_validation_vr/estimation_wwo27F_518R.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/cross_validation_vr\"\n",
    "\n",
    "region = [\"full\", \"wwo27F_337R\", \"337F_518R\", \"518F_800R\", \"wwo27F_518R\"]\n",
    "n_region = len(region)\n",
    "res = {}\n",
    "\n",
    "true_vals_path = \"../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "for r in region:\n",
    "    estimated_vals = pd.read_csv(f\"../../data/cross_validation_vr/estimation_{r}.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "    cmp = pd.merge(estimated_vals, true_vals, left_on='sequence', right_on=\"species_tax_id\", how='inner', suffixes=['_e', '_t'])\n",
    "\n",
    "    def get_xy_vals(cmp, t):\n",
    "        known_flag = (~cmp[t+'_t'].isnull()) & (~cmp[t+'_e'].isnull())\n",
    "        estimated_vals, true_vals = cmp[known_flag][t+'_e'], cmp[known_flag][t+'_t']\n",
    "        return estimated_vals, true_vals\n",
    "\n",
    "    res[r] = []\n",
    "    for t in nt:\n",
    "        x, y = get_xy_vals(cmp, t)\n",
    "        res[r] += [x.astype(float).corr(y.astype(float), method=\"pearson\")]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "y = np.arange(n_region, (n_region + 1) * len(nt), n_region + 1)\n",
    "for i, r in enumerate(region):\n",
    "    ax.barh(y-i, list(reversed(res[r])), height=1, color=cmap1.colors[i]) # From top to bottom\n",
    "\n",
    "ax.legend([\"Full\", \"V1-V2\", \"V3\", \"V4\", \"V1-V3\"],\n",
    "          title='Variable region',\n",
    "          edgecolor=(0.9, 0.9, 0.9),\n",
    "          facecolor='white',\n",
    "          bbox_to_anchor=(1.01, 0.), loc='lower left')\n",
    "\n",
    "ax.set_xlabel('Accuracy (Pearson Correlation Coefficient)')\n",
    "ax.set_yticks(y-2)\n",
    "ax.set_yticklabels(list(reversed([titles[t] for t in nt])))\n",
    "ax.set_title('11 continuous traits', fontsize=10)\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "ax.spines['top'].set(alpha=0.1, color='grey')\n",
    "ax.spines['right'].set(alpha=0.1, color='grey')\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.2))\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.grid(axis='x', alpha=0.1, color='grey')\n",
    "\n",
    "plt.savefig(\"../../results/03_cross_validation/figS3a.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [\"full\", \"wwo27F_337R\", \"337F_518R\", \"518F_800R\", \"wwo27F_518R\"]\n",
    "n_region = len(region)\n",
    "res = {}\n",
    "\n",
    "true_vals_path = \"../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "for r in region:\n",
    "    estimated_vals = pd.read_csv(f\"../../data/cross_validation_vr/estimation_{r}.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "    cmp = pd.merge(estimated_vals, true_vals, left_on='sequence', right_on=\"species_tax_id\", how='inner', suffixes=['_e', '_t'])\n",
    "\n",
    "    def get_xy_vals(cmp, t):\n",
    "        known_flag = (~cmp[t+'_t'].isnull()) & (~cmp[t+'_e'].isnull())\n",
    "        estimated_vals, true_vals = cmp[known_flag][t+'_e'], cmp[known_flag][t+'_t']\n",
    "        return estimated_vals, true_vals\n",
    "\n",
    "    res[r] = []\n",
    "    for t in ct:\n",
    "        x, y = get_xy_vals(cmp, t)\n",
    "        res[r] += [x.astype(float).corr(y.astype(float), method=\"pearson\")]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "y = np.arange(n_region, (n_region + 1) * len(ct), n_region + 1)\n",
    "for i, r in enumerate(region):\n",
    "    ax.barh(y-i, list(reversed(res[r])), height=1, color=cmap1.colors[i]) # From top to bottom\n",
    "\n",
    "ax.legend([\"Full\", \"V1-V2\", \"V3\", \"V4\", \"V1-V3\"],\n",
    "          title='Variable region',\n",
    "          edgecolor=(0.9, 0.9, 0.9),\n",
    "          facecolor='white',\n",
    "          bbox_to_anchor=(1.01, 0.), loc='lower left')\n",
    "\n",
    "ax.set_xlabel('Accuracy (Matthews Correlation Coefficient)')\n",
    "ax.set_yticks(y-2)\n",
    "ax.set_yticklabels(list(reversed([titles[t] for t in ct])))\n",
    "ax.set_title('16 categorical traits', fontsize=10)\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "ax.spines['top'].set(alpha=0.1, color='grey')\n",
    "ax.spines['right'].set(alpha=0.1, color='grey')\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.2))\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.grid(axis='x', alpha=0.1, color='grey')\n",
    "\n",
    "plt.savefig(\"../../results/03_cross_validation/figS3b.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bac2feature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
