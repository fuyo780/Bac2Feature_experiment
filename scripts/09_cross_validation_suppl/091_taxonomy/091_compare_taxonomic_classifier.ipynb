{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare variations in taxonomy-based prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomic classifications\n",
    "\n",
    "```sh\n",
    "conda activate qiime2-2023.5\n",
    "\n",
    "# Prepare directories\n",
    "mkdir ../../../data/cross_validation_suppl/q2_consensus_blast ../../../data/cross_validation_suppl/q2_consensus_vsearch\n",
    "for i in `seq 0 9`; do mkdir -p ../../../data/cross_validation_suppl/q2_consensus_blast/split_$i; done\n",
    "for i in `seq 0 9`; do mkdir -p ../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i; done\n",
    "\n",
    "# Cross-validation: BLAST-consensus-classifier\n",
    "qiime feature-classifier classify-consensus-blast --i-query ../../../data/cross_validation/split_$i/test_seq_full.qza --i-reference-reads ../../../data/cross_validation/split_$i/ref_seq_full.qza --i-reference-taxonomy ../../../data/cross_validation/split_$i/ref_taxonomy.qza --o-classification ../../../data/cross_validation_suppl/q2_consensus_blast/split_$i/test_taxonomy.qza --o-search-results ../../../data/cross_validation_suppl/q2_consensus_blast/split_$i/search_results.qza\n",
    "\n",
    "# Cross-validation: VSEARCH-consensus-classifier\n",
    "qiime feature-classifier classify-consensus-blast --i-query ../../../data/cross_validation/split_$i/test_seq_full.qza --i-reference-reads ../../../data/cross_validation/split_$i/ref_seq_full.qza --i-reference-taxonomy ../../../data/cross_validation/split_$i/ref_taxonomy.qza --o-classification ../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/test_taxonomy.qza --o-search-results ../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/search_results.qza\n",
    "\n",
    "# Export: BLAST-consensus-classifier\n",
    "for i in `seq 0 9`; do qiime tools export --input-path .../../../data/cross_validation_suppl/q2_consensus_blast/split_$i/test_taxonomy.qza --output-path ../../../data/cross_validation_suppl/q2_consensus_blast/split_$i/; done\n",
    "for i in `seq 0 9`; do qiime tools export --input-path .../../../data/cross_validation_suppl/q2_consensus_blast/split_$i/search_results.qza --output-path .../../../data/cross_validation_suppl/q2_consensus_blast/split_$i/; done\n",
    "\n",
    "# Export: VSEARCH-consensus-classifier\n",
    "for i in `seq 0 9`; do qiime tools export --input-path .../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/test_taxonomy.qza --output-path ../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/; done\n",
    "for i in `seq 0 9`; do qiime tools export --input-path .../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/search_results.qza --output-path .../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/; done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import mannwhitneyu, wilcoxon, friedmanchisquare\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "matplotlib.rcParams['font.family']       = 'Arial'\n",
    "matplotlib.rcParams['font.sans-serif']   = [\"Arial\",\"DejaVu Sans\",\"Lucida Grande\",\"Verdana\"]\n",
    "matplotlib.rcParams['figure.figsize']    = [4,3]\n",
    "matplotlib.rcParams['font.size']         = 10\n",
    "matplotlib.rcParams[\"axes.labelcolor\"]   = \"#000000\"\n",
    "matplotlib.rcParams[\"axes.linewidth\"]    = 1.0\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 1.0\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 1.0\n",
    "cmap1 = plt.cm.tab20\n",
    "cmap2 = plt.cm.Set3\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_emp(tax_dict, emp_trait, t, is_binary=False):\n",
    "    emp = emp_trait[t]\n",
    "    res = None\n",
    "    for k, v in list(reversed(tax_dict.items())):\n",
    "        if v in emp[k] and emp[k][v] != \"NA\":\n",
    "            res = emp[k][v]\n",
    "            break\n",
    "    if res is None:\n",
    "        return res\n",
    "    if is_binary:\n",
    "        res = decimal.Decimal(str(res)).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_DOWN)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clades = [\"superkingdom\", \"phylum\", \"class\",\n",
    "          \"order\", \"family\", \"genus\", \"species\"]\n",
    "prefix = [\"k__\", \"p__\", \"c__\", \"o__\", \"f__\", \"g__\", \"s__\"]\n",
    "\n",
    "nt = ['cell_diameter', 'cell_length', 'doubling_h', 'growth_tmp', 'optimum_tmp', 'optimum_ph', 'genome_size', 'gc_content', 'coding_genes', 'rRNA16S_genes', 'tRNA_genes']\n",
    "\n",
    "ct = ['gram_stain',\n",
    "      'sporulation', 'motility', 'range_salinity', 'facultative_respiration',\n",
    "      'anaerobic_respiration', 'aerobic_respiration', 'mesophilic_range_tmp',\n",
    "      'thermophilic_range_tmp', 'psychrophilic_range_tmp',\n",
    "      'bacillus_cell_shape', 'coccus_cell_shape', 'filament_cell_shape',\n",
    "      'coccobacillus_cell_shape', 'vibrio_cell_shape', 'spiral_cell_shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from taxonomic classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2-consensus-blast\n",
    "\n",
    "for i in range(10):\n",
    "    # Empirical trait distribution\n",
    "    emp_file = open(f'../../../data/cross_validation/split_{i}/empirical_dict.json', 'r')\n",
    "    emp_trait = json.load(emp_file)\n",
    "    emp_file.close()\n",
    "\n",
    "    result_path = f\"../../../data/cross_validation_suppl/q2_consensus_blast/split_{i}/taxonomy.tsv\"\n",
    "    naive_bayes_result = pd.read_csv(result_path, sep=\"\\t\")\n",
    "\n",
    "    x = naive_bayes_result[\"Taxon\"].str.split(\"; \", expand=True)\n",
    "    assigned_clades = clades[:x.shape[1]]\n",
    "    x = x.set_axis(assigned_clades, axis=\"columns\")\n",
    "    x = x.fillna(\"\")\n",
    "    for c, p in zip(assigned_clades, prefix):\n",
    "        x[c] = x[c].str.replace(p, \"\")\n",
    "    naive_bayes_result = pd.concat([naive_bayes_result, x], axis=1)\n",
    "    naive_bayes_result[\"tax_dict\"] = naive_bayes_result[assigned_clades].apply(\n",
    "                                            lambda df: df.to_dict(), axis=1\n",
    "                                        )\n",
    "\n",
    "    for t in nt:\n",
    "        naive_bayes_result[t] = naive_bayes_result[\"tax_dict\"].apply(\n",
    "                                    lambda x: predict_from_emp(x, emp_trait, t)\n",
    "                                )\n",
    "\n",
    "    for t in ct:\n",
    "        naive_bayes_result[t] = naive_bayes_result[\"tax_dict\"].apply(\n",
    "                                    lambda x: predict_from_emp(x, emp_trait, t, is_binary=True)\n",
    "                                )\n",
    "\n",
    "    # Save\n",
    "    estimation_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_blast/split_{i}/estimation_naive.tsv\"\n",
    "    naive_bayes_result.rename(columns={'Feature ID': 'sequence'}, inplace=True)\n",
    "    naive_bayes_result[[\"sequence\"]+nt+ct].to_csv(estimation_result_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2-consensus-vsearch\n",
    "\n",
    "for i in range(10):\n",
    "    # Empirical trait distribution\n",
    "    emp_file = open(f'../../../data/cross_validation/split_{i}/empirical_dict.json', 'r')\n",
    "    emp_trait = json.load(emp_file)\n",
    "    emp_file.close()\n",
    "\n",
    "    result_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/taxonomy.tsv\"\n",
    "    naive_bayes_result = pd.read_csv(result_path, sep=\"\\t\")\n",
    "\n",
    "    x = naive_bayes_result[\"Taxon\"].str.split(\"; \", expand=True)\n",
    "    assigned_clades = clades[:x.shape[1]]\n",
    "    x = x.set_axis(assigned_clades, axis=\"columns\")\n",
    "    x = x.fillna(\"\")\n",
    "    for c, p in zip(assigned_clades, prefix):\n",
    "        x[c] = x[c].str.replace(p, \"\")\n",
    "\n",
    "    naive_bayes_result = pd.concat([naive_bayes_result, x], axis=1)\n",
    "\n",
    "    naive_bayes_result[\"tax_dict\"] = naive_bayes_result[assigned_clades].apply(\n",
    "                                            lambda df: df.to_dict(), axis=1\n",
    "                                        )\n",
    "    for t in nt:\n",
    "        naive_bayes_result[t] = naive_bayes_result[\"tax_dict\"].apply(\n",
    "                                    lambda x: predict_from_emp(x, emp_trait, t)\n",
    "                                )\n",
    "    for t in ct:\n",
    "        naive_bayes_result[t] = naive_bayes_result[\"tax_dict\"].apply(\n",
    "                                    lambda x: predict_from_emp(x, emp_trait, t, is_binary=True)\n",
    "                                )\n",
    "\n",
    "    # Save\n",
    "    estimation_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/estimation_naive.tsv\"\n",
    "    naive_bayes_result.rename(columns={'Feature ID': 'sequence'}, inplace=True)\n",
    "    naive_bayes_result[[\"sequence\"]+nt+ct].to_csv(estimation_result_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_and_true_df(pred_vals_path, true_vals_path):\n",
    "    # Prediction\n",
    "    pred_vals = pd.read_csv(pred_vals_path, sep=\"\\t\")\n",
    "    pred_vals[\"sequence\"] = pred_vals[\"sequence\"].astype(str)\n",
    "    # Reference\n",
    "    true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "    cmp = pd.merge(pred_vals, true_vals,\n",
    "                   left_on='sequence', right_on=\"species_tax_id\", how='inner', suffixes=['_e', '_t'])\n",
    "    return cmp\n",
    "\n",
    "def remove_null_values(cmp, t, dtype):\n",
    "    known_flag = (~cmp[t+'_t'].isnull()) & (~cmp[t+'_e'].isnull())\n",
    "    pred_vals, true_vals = cmp[known_flag][t+'_e'], cmp[known_flag][t+'_t']\n",
    "    if dtype == 'float':\n",
    "        pred_vals = pred_vals.astype(float)\n",
    "        true_vals = true_vals.astype(float)\n",
    "    elif dtype == 'int':\n",
    "        pred_vals = pred_vals.astype(int)\n",
    "        true_vals = true_vals.astype(int)\n",
    "    return pred_vals, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significance_bar(x1, x2, y, h, pval, ax):\n",
    "    if pval < 0.05:\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1, c='black')\n",
    "        ax.text(float((x1+x2))/2, y+2*h, '*', ha='center', va='top')\n",
    "    return\n",
    "\n",
    "def calc_wilcoxon_signed(res_all_melt, t, permutation=False):\n",
    "    res_trait = res_all_melt[res_all_melt['trait'] == t]\n",
    "    y1 = res_trait[res_trait['method']=='Naive-Bayes']['accuracy']\n",
    "    y2 = res_trait[res_trait['method']=='BLAST+']['accuracy']\n",
    "    y3 = res_trait[res_trait['method']=='VSEARCH']['accuracy']\n",
    "    p1 = wilcoxon(y1, y2, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    p2 = wilcoxon(y2, y3, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    p3 = wilcoxon(y3, y1, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    return p1, p2, p3\n",
    "\n",
    "def prep_xy_for_sig_bar(x_num, y, h, s):\n",
    "    x1s = x_num\n",
    "    x2s = x_num[1:] + x_num[:1]\n",
    "    ys = [y, y + s * h, y + 2 * s * h]\n",
    "    return x1s, x2s, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals_path = \"../../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # q2_feature_classifier\n",
    "    nb_result_path = f\"../../../data/cross_validation/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=nb_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_q2_feature_classifier = []\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_q2_feature_classifier += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # q2_consensus_blast\n",
    "    nb_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_blast/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=nb_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_q2_consensus_blast = []\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_q2_consensus_blast += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # q2_consensus_vsearch\n",
    "    nb_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=nb_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_q2_consensus_vsearch = []\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_q2_consensus_vsearch += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": nt,\n",
    "                        \"Naive-Bayes\": res_list_q2_feature_classifier,\n",
    "                        \"BLAST+\": res_list_q2_consensus_blast,\n",
    "                        \"VSEARCH\": res_list_q2_consensus_vsearch})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_nt = tmp\n",
    "    else:\n",
    "        res_all_nt = pd.concat([res_all_nt, tmp], axis=0)\n",
    "\n",
    "res_all_melt_nt = res_all_nt.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'cell_diameter': 'Cell diameter', 'cell_length': 'Cell length', 'doubling_h': 'Doubling time', 'growth_tmp': 'Growth temp.', 'optimum_tmp': 'Optimum temp.', 'optimum_ph': 'Optimum pH', 'genome_size': 'Genome size', 'gc_content': 'GC content', 'coding_genes': 'Coding genes', 'rRNA16S_genes': 'rRNA16S genes', 'tRNA_genes': 'tRNA genes', 'gram_stain': 'Gram stain', 'sporulation': 'Sporulation', 'motility': 'Motility', 'range_salinity': 'Halophile', 'facultative_respiration': 'Facultative', 'anaerobic_respiration': 'Anaerobe', 'aerobic_respiration':'Aerobe' ,'mesophilic_range_tmp': 'Mesophile', 'thermophilic_range_tmp':'Thermophile', 'psychrophilic_range_tmp': 'Psychrophile', 'bacillus_cell_shape': 'Bacillus', 'coccus_cell_shape': 'Coccus', 'filament_cell_shape': 'Filament', 'coccobacillus_cell_shape': 'Coccobacillus', 'vibrio_cell_shape': 'Vibrio', 'spiral_cell_shape': 'Spiral'}\n",
    "\n",
    "ntraits = len(nt)\n",
    "ncols = 4\n",
    "nrows = math.ceil(float(ntraits) / ncols)\n",
    "pvals_list = []\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(1.5*ncols, 1.5*nrows))\n",
    "\n",
    "for i, t in enumerate(nt):\n",
    "    ax = axes.flatten()[i]\n",
    "    x = res_all_melt_nt[res_all_melt_nt[\"trait\"]==t]\n",
    "    sns.boxplot(data=x, x=\"method\", y=\"accuracy\", hue=\"method\", ax=ax,\n",
    "                palette=\"Set2\", fill=False, linewidth=1.3, showfliers=False)\n",
    "    sns.stripplot(data=x, x=\"method\", y=\"accuracy\",\n",
    "                  ax=ax, color=\"black\", size=3, jitter=0.2)\n",
    "    ax.set_title(titles[t])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticks(range(len(x[\"method\"].unique())))\n",
    "    if i // ncols == nrows - 1:\n",
    "        ax.set_xticklabels([\"Naïve-Bayes\", \"BLAST+\", \"VSEARCH\"], rotation=90)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if i % ncols == 0:\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_ylim(-.05, 1.05)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.50))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    p1, p2, p3 = calc_wilcoxon_signed(res_all_melt=res_all_melt_nt, t=t)\n",
    "    pvals_list += [[p1, p2, p3]]\n",
    "\n",
    "pvals_1d = [p for pvals in pvals_list for p in pvals if not np.isnan(p)]\n",
    "pvals_idx = [np.isnan(pvals[0]) or np.isnan(pvals[1]) or np.isnan(pvals[2]) for pvals in pvals_list]\n",
    "fdr_result = multipletests(pvals=pvals_1d, alpha=0.05, method=\"fdr_bh\")\n",
    "pvals_modified_1d = fdr_result[1]\n",
    "pvals_modified_2d = pvals_modified_1d.reshape(-1, 3)\n",
    "\n",
    "for pvals, idx, ax in zip(pvals_modified_2d, pvals_idx, axes.flatten()):\n",
    "    if idx:\n",
    "        continue\n",
    "    x1s, x2s, ys = prep_xy_for_sig_bar(x_num=list(np.arange(3)), y=0.25, h=-0.01, s=8)\n",
    "    for x1, x2, y, pval in zip(x1s, x2s, ys, pvals):\n",
    "        plot_significance_bar(x1=x1, x2=x2, y=y, h=-0.02, pval=pval, ax=ax)\n",
    "\n",
    "axes.flatten()[-1].set_axis_off()\n",
    "fig.supxlabel(\"Variation of taxonomic classification methods\")\n",
    "fig.supylabel(\"Pearson Correlation Coefficients of predicted and actual trait values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../../results/09_cross_validation_suppl/figS3a.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals_path = \"../../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # q2_feature_classifier\n",
    "    nb_result_path = f\"../../../data/cross_validation/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=nb_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_q2_feature_classifier = [] # 予測値と真の値の相関\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_q2_feature_classifier += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # q2_consensus_blast\n",
    "    nb_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_blast/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=nb_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_q2_consensus_blast = [] # 予測値と真の値の相関\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_q2_consensus_blast += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # q2_consensus_vsearch\n",
    "    nb_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/estimation_naive.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=nb_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_q2_consensus_vsearch = [] # 予測値と真の値の相関\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_q2_consensus_vsearch += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": ct,\n",
    "                        \"Naive-Bayes\": res_list_q2_feature_classifier,\n",
    "                        \"BLAST+\": res_list_q2_consensus_blast,\n",
    "                        \"VSEARCH\": res_list_q2_consensus_vsearch})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_ct = tmp\n",
    "    else:\n",
    "        res_all_ct = pd.concat([res_all_ct, tmp], axis=0)\n",
    "\n",
    "res_all_melt_ct = res_all_ct.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntraits = len(ct)\n",
    "ncols = 4\n",
    "nrows = math.ceil(float(ntraits) / ncols)\n",
    "pvals_list = []\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(1.5*ncols, 1.5*nrows))\n",
    "\n",
    "for i, t in enumerate(ct):\n",
    "    ax = axes.flatten()[i]\n",
    "    x = res_all_melt_ct[res_all_melt_ct[\"trait\"]==t]\n",
    "    sns.boxplot(data=x, x=\"method\", y=\"accuracy\", hue=\"method\", ax=ax, order=[\"Naive-Bayes\", \"BLAST+\", \"VSEARCH\"],\n",
    "                palette=\"Set2\", fill=False, linewidth=1.3, showfliers=False)\n",
    "    sns.stripplot(data=x, x=\"method\", y=\"accuracy\", order=[\"Naive-Bayes\", \"BLAST+\", \"VSEARCH\"],\n",
    "                  ax=ax, color=\"black\", size=3, jitter=0.2)\n",
    "    ax.set_title(titles[t])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticks(range(len(x[\"method\"].unique())))\n",
    "    if i // ncols == nrows - 1:\n",
    "        ax.set_xticklabels([\"Naïve-Bayes\", \"BLAST+\", \"VSEARCH\"], rotation=90)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if i % ncols == 0:\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_ylim(-.05, 1.05)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.50))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    p1, p2, p3 = calc_wilcoxon_signed(res_all_melt=res_all_melt_ct, t=t)\n",
    "    pvals_list += [[p1, p2, p3]]\n",
    "\n",
    "pvals_1d = [p for pvals in pvals_list for p in pvals if not np.isnan(p)]\n",
    "pvals_idx = [np.isnan(pvals[0]) or np.isnan(pvals[1]) or np.isnan(pvals[2]) for pvals in pvals_list]\n",
    "fdr_result = multipletests(pvals=pvals_1d, alpha=0.05, method=\"fdr_bh\")\n",
    "pvals_modified_1d = fdr_result[1]\n",
    "pvals_modified_2d = pvals_modified_1d.reshape(-1, 3)\n",
    "\n",
    "for pvals, idx, ax in zip(pvals_modified_2d, pvals_idx, axes.flatten()):\n",
    "    if idx:\n",
    "        continue\n",
    "    x1s, x2s, ys = prep_xy_for_sig_bar(x_num=list(np.arange(3)), y=0.25, h=-0.01, s=8)\n",
    "    for x1, x2, y, pval in zip(x1s, x2s, ys, pvals):\n",
    "        plot_significance_bar(x1=x1, x2=x2, y=y, h=-0.02, pval=pval, ax=ax)\n",
    "\n",
    "fig.supxlabel(\"Variation of taxonomic classification methods\")\n",
    "fig.supylabel(\"Matthews Correlation Coefficients of predicted and actual trait values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../../results/09_cross_validation_suppl/figS3b.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bac2feature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
