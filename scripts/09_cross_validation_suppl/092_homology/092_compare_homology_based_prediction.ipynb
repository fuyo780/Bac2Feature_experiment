{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f667b4c",
   "metadata": {},
   "source": [
    "# Compare variations in homology-based prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a34e8",
   "metadata": {},
   "source": [
    "## Homology search\n",
    "\n",
    "```sh\n",
    "conda activate qiime2-2023.5\n",
    "\n",
    "# Prepare directories\n",
    "mkdir ../../../data/cross_validation_suppl/sortmerna\n",
    "for i in `seq 0 9`; do mkdir -p ../../../data/cross_validation_suppl/sortmerna/split_$i; done\n",
    "\n",
    "# VSEARCH: export previous results\n",
    "for i in `seq 0 9`; do qiime tools export --input-path ../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/search_results.qza --output-path ../../../data/cross_validation_suppl/q2_consensus_vsearch/split_$i/; done\n",
    "\n",
    "# SortMeRNA: Make reference\n",
    "for i in `seq 0 9`; do indexdb_rna --ref ../../../data/cross_validation/split_$i/ref_seq_full.fasta,../../../data/cross_validation_suppl/sortmerna/split_$i/ref_seq_full.idx; done\n",
    "\n",
    "# SortMeRNA: Cross-validation\n",
    "for i in `seq 0 9`; do sortmerna --ref ../../../data/cross_validation/split_$i/ref_seq_full.fasta,../../../data/cross_validation_suppl/sortmerna/split_$i/ref_seq_full.idx --reads ../../../data/cross_validation/split_$i/test_seq_full.fasta --blast 1 --other ../../../data/cross_validation_suppl/sortmerna/split_$i/sortmerna_out --fastx --best 10 --min_lis 10 --aligned ../../../data/cross_validation_suppl/sortmerna/split_$i/aligned.out --log; done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f297076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "\n",
    "from scipy.stats import mannwhitneyu, wilcoxon, friedmanchisquare\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "matplotlib.rcParams['font.family']       = 'Arial'\n",
    "matplotlib.rcParams['font.sans-serif']   = [\"Arial\",\"DejaVu Sans\",\"Lucida Grande\",\"Verdana\"]\n",
    "matplotlib.rcParams['figure.figsize']    = [4,3]\n",
    "matplotlib.rcParams['font.size']         = 10\n",
    "matplotlib.rcParams[\"axes.labelcolor\"]   = \"#000000\"\n",
    "matplotlib.rcParams[\"axes.linewidth\"]    = 1.0\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 1.0\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 1.0\n",
    "cmap1 = plt.cm.tab20\n",
    "cmap2 = plt.cm.Set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trait = pd.read_csv(\"../../../data/ref_bac2feature/trait_bac2feature.tsv\", sep=\"\\t\")\n",
    "trait[\"species_tax_id\"] = trait[\"species_tax_id\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350fe2a",
   "metadata": {},
   "source": [
    "## Prediction from homology search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9200b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_blast_result(blast_result: pd.DataFrame, perc_identity: float):\n",
    "    \"\"\"Preprocess the data according to the alignment length and percent identity.\"\"\"\n",
    "    # Convert columns to numeric\n",
    "    blast_result[['pident', 'length']] = blast_result[['pident', 'length']].astype(float)\n",
    "\n",
    "    # Filter by percentage identity, if provided\n",
    "    if perc_identity is not None:\n",
    "        blast_result = blast_result[blast_result['pident'] >= perc_identity]\n",
    "\n",
    "    # Exclude very short sequences based on half the average length\n",
    "    min_length = blast_result['length'].mean() * 0.5\n",
    "    blast_result = blast_result[blast_result['length'] >= min_length]\n",
    "    blast_result.reset_index()\n",
    "\n",
    "    return blast_result\n",
    "\n",
    "def summarize_traits(res_trait, trait_cols):\n",
    "    \"\"\"Summarize traits for each sequence based on non-null entries.\"\"\"\n",
    "    bests = [\n",
    "        res_trait.loc[res_trait[col].notnull()].drop_duplicates(subset='sequence', keep='first')[[col, 'pident']].rename(columns={'pident': f'{col}_pident'})\n",
    "        for col in trait_cols\n",
    "    ]\n",
    "    out_trait = pd.concat(bests, axis=1)\n",
    "    out_trait = pd.concat([res_trait['sequence'].drop_duplicates(keep='first'), out_trait], axis=1)\n",
    "    return out_trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    in_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/blast6.tsv\"\n",
    "    blast_result = pd.read_csv(in_path, sep=\"\\t\", header=None)\n",
    "    blast_result.columns = [\"sequence\", \"species_tax_id\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\"]\n",
    "    blast_result[\"species_tax_id\"] = blast_result[\"species_tax_id\"].astype(\"str\")\n",
    "\n",
    "    # Filter the blast result based on the percent identity\n",
    "    blast_result = preprocess_blast_result(blast_result, perc_identity=None)\n",
    "\n",
    "    # Merge with trait data\n",
    "    res_trait = pd.merge(blast_result, trait, how='left', on='species_tax_id')\n",
    "\n",
    "    # Summarize the predicted traits for each sequences\n",
    "    res_trait.set_index('sequence', drop=False, inplace=True)\n",
    "    summarized_trait = summarize_traits(res_trait, trait.columns[1:])\n",
    "\n",
    "    out_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/prediction_homology.tsv\"\n",
    "    summarized_trait.to_csv(out_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    in_path = f\"../../../data/cross_validation_suppl/sortmerna/split_{i}/aligned.out.blast\"\n",
    "    blast_result = pd.read_csv(in_path, sep=\"\\t\", header=None)\n",
    "    blast_result.columns = [\"sequence\", \"species_tax_id\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\"]\n",
    "    blast_result[\"species_tax_id\"] = blast_result[\"species_tax_id\"].astype(\"str\")\n",
    "\n",
    "    # Filter the blast result based on the percent identity\n",
    "    blast_result = preprocess_blast_result(blast_result, perc_identity=None)\n",
    "\n",
    "    # Merge with trait data\n",
    "    res_trait = pd.merge(blast_result, trait, how='left', on='species_tax_id')\n",
    "\n",
    "    # Summarize the predicted traits for each sequences\n",
    "    res_trait.set_index('sequence', drop=False, inplace=True)\n",
    "    summarized_trait = summarize_traits(res_trait, trait.columns[1:])\n",
    "\n",
    "    out_path = f\"../../../data/cross_validation_suppl/sortmerna/split_{i}/prediction_homology.tsv\"\n",
    "    summarized_trait.to_csv(out_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1c136",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7073ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_and_true_df(pred_vals_path, true_vals_path):\n",
    "    # Prediction\n",
    "    pred_vals = pd.read_csv(pred_vals_path, sep=\"\\t\")\n",
    "    pred_vals[\"sequence\"] = pred_vals[\"sequence\"].astype(str)\n",
    "    # Reference\n",
    "    true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "    cmp = pd.merge(pred_vals, true_vals,\n",
    "                   left_on='sequence', right_on=\"species_tax_id\", how='inner', suffixes=['_e', '_t'])\n",
    "    return cmp\n",
    "\n",
    "def remove_null_values(cmp, t, dtype):\n",
    "    known_flag = (~cmp[t+'_t'].isnull()) & (~cmp[t+'_e'].isnull())\n",
    "    pred_vals, true_vals = cmp[known_flag][t+'_e'], cmp[known_flag][t+'_t']\n",
    "    if dtype == 'float':\n",
    "        pred_vals = pred_vals.astype(float)\n",
    "        true_vals = true_vals.astype(float)\n",
    "    elif dtype == 'int':\n",
    "        pred_vals = pred_vals.astype(int)\n",
    "        true_vals = true_vals.astype(int)\n",
    "    return pred_vals, true_vals\n",
    "\n",
    "nt = ['cell_diameter', 'cell_length', 'doubling_h', 'growth_tmp', 'optimum_tmp', 'optimum_ph', 'genome_size', 'gc_content', 'coding_genes', 'rRNA16S_genes', 'tRNA_genes']\n",
    "\n",
    "ct = ['gram_stain',\n",
    "      'sporulation', 'motility', 'range_salinity', 'facultative_respiration',\n",
    "      'anaerobic_respiration', 'aerobic_respiration', 'mesophilic_range_tmp',\n",
    "      'thermophilic_range_tmp', 'psychrophilic_range_tmp',\n",
    "      'bacillus_cell_shape', 'coccus_cell_shape', 'filament_cell_shape',\n",
    "      'coccobacillus_cell_shape', 'vibrio_cell_shape', 'spiral_cell_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals_path = \"../../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # BLAST\n",
    "    blast_result_path = f\"../../../data/cross_validation/split_{i}/estimation_blast.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=blast_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_blast = [] # 予測値と真の値の相関\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_blast += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # VSEARCH\n",
    "    vsearch_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/prediction_homology.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=vsearch_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_vsearch = [] # 予測値と真の値の相関\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_vsearch += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # SortMeRNA\n",
    "    sortmerna_result_path = f\"../../../data/cross_validation_suppl/sortmerna/split_{i}/prediction_homology.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=sortmerna_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_sortmerna = [] # 予測値と真の値の相関\n",
    "    for t in nt:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_sortmerna += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": nt,\n",
    "                        \"BLAST\": res_list_blast,\n",
    "                        \"VSEARCH\": res_list_vsearch,\n",
    "                        \"SortMeRNA\": res_list_sortmerna})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_nt = tmp\n",
    "    else:\n",
    "        res_all_nt = pd.concat([res_all_nt, tmp], axis=0)\n",
    "\n",
    "res_all_melt_nt = res_all_nt.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significance_bar(x1, x2, y, h, pval, ax):\n",
    "    if pval < 0.05:\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1, c='black')\n",
    "        ax.text(float((x1+x2))/2, y+2*h, '*', ha='center', va='top')\n",
    "    return\n",
    "\n",
    "def calc_wilcoxon_signed(res_all_melt, t, permutation=False):\n",
    "    res_trait = res_all_melt[res_all_melt['trait'] == t]\n",
    "    y1 = res_trait[res_trait['method']=='BLAST']['accuracy']\n",
    "    y2 = res_trait[res_trait['method']=='VSEARCH']['accuracy']\n",
    "    y3 = res_trait[res_trait['method']=='SortMeRNA']['accuracy']\n",
    "    p1 = wilcoxon(y1, y2, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    p2 = wilcoxon(y2, y3, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    p3 = wilcoxon(y3, y1, zero_method='wilcox', alternative='two-sided', method='exact').pvalue\n",
    "    return p1, p2, p3\n",
    "\n",
    "def prep_xy_for_sig_bar(x_num, y, h, s):\n",
    "    x1s = x_num\n",
    "    x2s = x_num[1:] + x_num[:1]\n",
    "    ys = [y, y + s * h, y + 2 * s * h]\n",
    "    return x1s, x2s, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {'cell_diameter': 'Cell diameter', 'cell_length': 'Cell length', 'doubling_h': 'Doubling time', 'growth_tmp': 'Growth temp.', 'optimum_tmp': 'Optimum temp.', 'optimum_ph': 'Optimum pH', 'genome_size': 'Genome size', 'gc_content': 'GC content', 'coding_genes': 'Coding genes', 'rRNA16S_genes': 'rRNA16S genes', 'tRNA_genes': 'tRNA genes', 'gram_stain': 'Gram stain', 'sporulation': 'Sporulation', 'motility': 'Motility', 'range_salinity': 'Halophile', 'facultative_respiration': 'Facultative', 'anaerobic_respiration': 'Anaerobe', 'aerobic_respiration':'Aerobe' ,'mesophilic_range_tmp': 'Mesophile', 'thermophilic_range_tmp':'Thermophile', 'psychrophilic_range_tmp': 'Psychrophile', 'bacillus_cell_shape': 'Bacillus', 'coccus_cell_shape': 'Coccus', 'filament_cell_shape': 'Filament', 'coccobacillus_cell_shape': 'Coccobacillus', 'vibrio_cell_shape': 'Vibrio', 'spiral_cell_shape': 'Spiral'}\n",
    "\n",
    "ntraits = len(nt)\n",
    "ncols = 4\n",
    "nrows = math.ceil(float(ntraits) / ncols)\n",
    "pvals_list = []\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(1.5*ncols, 1.5*nrows))\n",
    "\n",
    "for i, t in enumerate(nt):\n",
    "    ax = axes.flatten()[i]\n",
    "    x = res_all_melt_nt[res_all_melt_nt[\"trait\"]==t]\n",
    "    sns.boxplot(data=x, x=\"method\", y=\"accuracy\", hue=\"method\", ax=ax,\n",
    "                palette=\"Set2\", fill=False, linewidth=1.3, showfliers=False)\n",
    "    sns.stripplot(data=x, x=\"method\", y=\"accuracy\",\n",
    "                  ax=ax, color=\"black\", size=3, jitter=0.2)\n",
    "    ax.set_title(titles[t])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticks(range(len(x[\"method\"].unique())))\n",
    "    if i // ncols == nrows - 1:\n",
    "        ax.set_xticklabels([\"BLAST+\", \"VSEARCH\", \"SortMeRNA\"], rotation=90)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if i % ncols == 0:\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_ylim(-.05, 1.05)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.50))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    p1, p2, p3 = calc_wilcoxon_signed(res_all_melt=res_all_melt_nt, t=t)\n",
    "    pvals_list += [[p1, p2, p3]]\n",
    "\n",
    "pvals_1d = [p for pvals in pvals_list for p in pvals if not np.isnan(p)]\n",
    "pvals_idx = [np.isnan(pvals[0]) or np.isnan(pvals[1]) or np.isnan(pvals[2]) for pvals in pvals_list]\n",
    "fdr_result = multipletests(pvals=pvals_1d, alpha=0.05, method=\"fdr_bh\")\n",
    "pvals_modified_1d = fdr_result[1]\n",
    "pvals_modified_2d = pvals_modified_1d.reshape(-1, 3)\n",
    "\n",
    "for pvals, idx, ax in zip(pvals_modified_2d, pvals_idx, axes.flatten()):\n",
    "    if idx:\n",
    "        continue\n",
    "    x1s, x2s, ys = prep_xy_for_sig_bar(x_num=list(np.arange(3)), y=0.25, h=-0.01, s=8)\n",
    "    for x1, x2, y, pval in zip(x1s, x2s, ys, pvals):\n",
    "        plot_significance_bar(x1=x1, x2=x2, y=y, h=-0.02, pval=pval, ax=ax)\n",
    "\n",
    "axes.flatten()[-1].set_axis_off()\n",
    "fig.supxlabel(\"Variation of homology search methods\")\n",
    "fig.supylabel(\"Pearson Correlation Coefficients of predicted and actual trait values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../../results/09_cross_validation_suppl/figS2a.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1598151",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals_path = \"../../../data/ref_bac2feature/trait_bac2feature.tsv\"\n",
    "true_vals = pd.read_csv(true_vals_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # BLAST\n",
    "    blast_result_path = f\"../../../data/cross_validation/split_{i}/estimation_blast.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=blast_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_blast = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_blast += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # VSEARCH\n",
    "    vsearch_result_path = f\"../../../data/cross_validation_suppl/q2_consensus_vsearch/split_{i}/prediction_homology.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=vsearch_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_vsearch = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_vsearch += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "    # SortMeRNA\n",
    "    sortmerna_result_path = f\"../../../data/cross_validation_suppl/sortmerna/split_{i}/prediction_homology.tsv\"\n",
    "    cmp = get_pred_and_true_df(pred_vals_path=sortmerna_result_path, true_vals_path=true_vals_path)\n",
    "    res_list_sortmerna = []\n",
    "    for t in ct:\n",
    "        pred_vals, true_vals = remove_null_values(cmp=cmp, t=t, dtype='float')\n",
    "        res_list_sortmerna += [pred_vals.corr(true_vals, method=\"pearson\")]\n",
    "\n",
    "\n",
    "    # Concat\n",
    "    tmp = pd.DataFrame({\"trait\": ct,\n",
    "                        \"BLAST\": res_list_blast,\n",
    "                        \"VSEARCH\": res_list_vsearch,\n",
    "                        \"SortMeRNA\": res_list_sortmerna})\n",
    "    tmp[\"split\"] = i\n",
    "    if i == 0:\n",
    "        res_all_ct = tmp\n",
    "    else:\n",
    "        res_all_ct = pd.concat([res_all_ct, tmp], axis=0)\n",
    "\n",
    "res_all_melt_ct = res_all_ct.melt(id_vars=['trait', 'split'], var_name='method', value_name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntraits = len(ct)\n",
    "ncols = 4\n",
    "nrows = math.ceil(float(ntraits) / ncols)\n",
    "pvals_list = []\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(1.5*ncols, 1.5*nrows))\n",
    "\n",
    "for i, t in enumerate(ct):\n",
    "    ax = axes.flatten()[i]\n",
    "    x = res_all_melt_ct[res_all_melt_ct[\"trait\"]==t]\n",
    "    sns.boxplot(data=x, x=\"method\", y=\"accuracy\", hue=\"method\", ax=ax,\n",
    "                palette=\"Set2\", fill=False, linewidth=1.3, showfliers=False)\n",
    "    sns.stripplot(data=x, x=\"method\", y=\"accuracy\",\n",
    "                  ax=ax, color=\"black\", size=3, jitter=0.2)\n",
    "    ax.set_title(titles[t])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticks(range(len(x[\"method\"].unique())))\n",
    "    if i // ncols == nrows - 1:\n",
    "        ax.set_xticklabels([\"BLAST+\", \"VSEARCH\", \"SortMeRNA\"], rotation=90)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if i % ncols == 0:\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_ylim(-.05, 1.05)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.50))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    p1, p2, p3 = calc_wilcoxon_signed(res_all_melt=res_all_melt_ct, t=t)\n",
    "    pvals_list += [[p1, p2, p3]]\n",
    "\n",
    "pvals_1d = [p for pvals in pvals_list for p in pvals if not np.isnan(p)]\n",
    "pvals_idx = [np.isnan(pvals[0]) or np.isnan(pvals[1]) or np.isnan(pvals[2]) for pvals in pvals_list]\n",
    "fdr_result = multipletests(pvals=pvals_1d, alpha=0.05, method=\"fdr_bh\")\n",
    "pvals_modified_1d = fdr_result[1]\n",
    "pvals_modified_2d = pvals_modified_1d.reshape(-1, 3)\n",
    "\n",
    "for pvals, idx, ax in zip(pvals_modified_2d, pvals_idx, axes.flatten()):\n",
    "    if idx:\n",
    "        continue\n",
    "    x1s, x2s, ys = prep_xy_for_sig_bar(x_num=list(np.arange(3)), y=0.25, h=-0.01, s=8)\n",
    "    for x1, x2, y, pval in zip(x1s, x2s, ys, pvals):\n",
    "        plot_significance_bar(x1=x1, x2=x2, y=y, h=-0.02, pval=pval, ax=ax)\n",
    "\n",
    "# axes.flatten()[-1].set_axis_off()\n",
    "fig.supxlabel(\"Variation of homology search methods\")\n",
    "fig.supylabel(\"Matthews Correlation Coefficients of predicted and actual trait values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../../results/09_cross_validation_suppl/figS2b.pdf\", format=\"pdf\", dpi=300, facecolor=\"white\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bac2feature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
